# ğŸš€ ETL GitHub Pipeline Project

This project is a fully containerized, modular end-to-end data engineering pipeline that ingests GitHub Archive data, transforms it using Apache Spark and Delta Lake, triggers an Azure Synapse pipeline, and models data using dbt â€” all orchestrated with Apache Airflow.

## ğŸ”§ Stack

- **Airflow** - Orchestration  
- **Python** - ETL scripting  
- **Apache Spark + Delta Lake** - Data transformation  
- **Azure Data Lake Storage Gen2** - Data storage  
- **Azure Synapse** - Data processing pipeline  
- **dbt** - Data modeling  
- **Terraform** - Infra as Code (Azure setup)  
- **Docker** - Ingestion container  
- **VSCode on Azure VM** - Dev environment  

## ğŸ“ Project Structure

```text
ETL-Github-Pipeline/
â”œâ”€â”€ dags/                   # Airflow DAGs
â”œâ”€â”€ ingestion/              # Dockerized data ingestion scripts
â”œâ”€â”€ transforms/             # PySpark + Synapse trigger + dbt
â”‚   â”œâ”€â”€ bronze_to_silver/   # Spark transformation scripts
â”‚   â””â”€â”€ silver_to_gold/     # Synapse trigger & dbt models
â”œâ”€â”€ utils/                  # Spark session helpers
â”œâ”€â”€ config/                 # YAML config files
â”œâ”€â”€ infra/                  # Terraform Azure setup
â”œâ”€â”€ tests/                  # Unit tests
â”œâ”€â”€ airflow-env/            # Python virtual environment
â”œâ”€â”€ requirements.txt        # Dependency list
â””â”€â”€ README.md               # Documentation
```
